{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3e1fc1",
   "metadata": {},
   "source": [
    "# 03 - Class to Node Type Mapping\n",
    "\n",
    "Translates OWL/RDFS classes to Fabric Graph node types.\n",
    "\n",
    "**Input**: `bronze_triples` Delta table\n",
    "**Output**: `silver_node_types` Delta table\n",
    "\n",
    "## Translation Rules\n",
    "\n",
    "| RDF Construct | LPG Equivalent |\n",
    "|---------------|----------------|\n",
    "| owl:Class / rdfs:Class | Node Type (label) |\n",
    "| rdfs:subClassOf | Node Type hierarchy |\n",
    "| rdfs:label | Display name |\n",
    "\n",
    "## Node Type Name Generation\n",
    "\n",
    "- Extract local name from IRI (after last `/` or `#`)\n",
    "- Remove special characters\n",
    "- Convert to PascalCase for consistency\n",
    "- Handle blank nodes with stable ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea3704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_TABLE = \"bronze_triples\"\n",
    "OUTPUT_TABLE = \"silver_node_types\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, ArrayType, StructType, StructField\n",
    "from typing import List, Dict, Optional, Set\n",
    "import re\n",
    "import json\n",
    "\n",
    "# RDF namespace constants\n",
    "RDF_TYPE = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"\n",
    "RDFS_CLASS = \"http://www.w3.org/2000/01/rdf-schema#Class\"\n",
    "RDFS_SUBCLASS_OF = \"http://www.w3.org/2000/01/rdf-schema#subClassOf\"\n",
    "RDFS_LABEL = \"http://www.w3.org/2000/01/rdf-schema#label\"\n",
    "RDFS_COMMENT = \"http://www.w3.org/2000/01/rdf-schema#comment\"\n",
    "OWL_CLASS = \"http://www.w3.org/2002/07/owl#Class\"\n",
    "OWL_THING = \"http://www.w3.org/2002/07/owl#Thing\"\n",
    "SKOS_PREFLABEL = \"http://www.w3.org/2004/02/skos/core#prefLabel\"\n",
    "SKOS_DEFINITION = \"http://www.w3.org/2004/02/skos/core#definition\"\n",
    "\n",
    "# Common namespace prefixes for display\n",
    "PREFIXES = {\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\": \"rdf:\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#\": \"rdfs:\",\n",
    "    \"http://www.w3.org/2002/07/owl#\": \"owl:\",\n",
    "    \"http://www.w3.org/2004/02/skos/core#\": \"skos:\",\n",
    "    \"http://www.w3.org/ns/shacl#\": \"sh:\",\n",
    "    \"http://www.w3.org/2001/XMLSchema#\": \"xsd:\",\n",
    "}\n",
    "\n",
    "def shorten_uri(uri: str) -> str:\n",
    "    \"\"\"Convert full URI to prefixed form for display.\"\"\"\n",
    "    if uri is None:\n",
    "        return None\n",
    "    for full, prefix in PREFIXES.items():\n",
    "        if uri.startswith(full):\n",
    "            return prefix + uri[len(full):]\n",
    "    return uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7062de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_local_name(uri: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the local name from a URI.\n",
    "    Examples:\n",
    "        http://example.org/ontology#PhysicalObject -> PhysicalObject\n",
    "        http://example.org/ontology/Building -> Building\n",
    "        _:blank123 -> blank123\n",
    "    \"\"\"\n",
    "    if uri is None:\n",
    "        return None\n",
    "    \n",
    "    # Handle blank nodes\n",
    "    if uri.startswith(\"_:\"):\n",
    "        return uri[2:]\n",
    "    \n",
    "    # Try hash fragment first\n",
    "    if \"#\" in uri:\n",
    "        return uri.split(\"#\")[-1]\n",
    "    \n",
    "    # Fall back to last path segment\n",
    "    if \"/\" in uri:\n",
    "        return uri.split(\"/\")[-1]\n",
    "    \n",
    "    return uri\n",
    "\n",
    "\n",
    "def sanitize_node_type_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert a name to a valid node type identifier.\n",
    "    - Remove special characters\n",
    "    - Convert to PascalCase\n",
    "    - Ensure starts with letter\n",
    "    \"\"\"\n",
    "    if name is None:\n",
    "        return None\n",
    "    \n",
    "    # Replace non-alphanumeric with space\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9]', ' ', name)\n",
    "    \n",
    "    # Split into words and capitalize each\n",
    "    words = cleaned.split()\n",
    "    pascal_case = ''.join(word.capitalize() for word in words if word)\n",
    "    \n",
    "    # Ensure starts with letter\n",
    "    if pascal_case and not pascal_case[0].isalpha():\n",
    "        pascal_case = \"Node\" + pascal_case\n",
    "    \n",
    "    return pascal_case if pascal_case else \"UnknownType\"\n",
    "\n",
    "\n",
    "# Register UDFs for Spark\n",
    "extract_local_name_udf = F.udf(extract_local_name, StringType())\n",
    "sanitize_name_udf = F.udf(sanitize_node_type_name, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1678cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bronze triples\n",
    "df_triples = spark.table(INPUT_TABLE)\n",
    "print(f\"Loaded {df_triples.count()} triples from '{INPUT_TABLE}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2721f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for property ranges/domains\n",
    "RDFS_DOMAIN = \"http://www.w3.org/2000/01/rdf-schema#domain\"\n",
    "RDFS_RANGE = \"http://www.w3.org/2000/01/rdf-schema#range\"\n",
    "OWL_OBJECT_PROPERTY = \"http://www.w3.org/2002/07/owl#ObjectProperty\"\n",
    "\n",
    "# Step 1: Find EXPLICIT classes (subjects typed as owl:Class or rdfs:Class)\n",
    "df_explicit_classes = df_triples.filter(\n",
    "    (F.col(\"predicate\") == RDF_TYPE) & \n",
    "    (F.col(\"object\").isin([OWL_CLASS, RDFS_CLASS]))\n",
    ").select(\n",
    "    F.col(\"subject\").alias(\"class_uri\"),\n",
    "    F.col(\"graph\")\n",
    ").distinct()\n",
    "\n",
    "print(f\"Found {df_explicit_classes.count()} explicit classes (owl:Class or rdfs:Class)\")\n",
    "\n",
    "# Step 2: Find IMPLIED classes from object property ranges\n",
    "# These are classes referenced as range of owl:ObjectProperty but not explicitly declared\n",
    "df_object_properties = df_triples.filter(\n",
    "    (F.col(\"predicate\") == RDF_TYPE) & \n",
    "    (F.col(\"object\") == OWL_OBJECT_PROPERTY)\n",
    ").select(F.col(\"subject\").alias(\"property_uri\")).distinct()\n",
    "\n",
    "df_range_classes = df_triples.filter(\n",
    "    F.col(\"predicate\") == RDFS_RANGE\n",
    ").join(\n",
    "    df_object_properties, \n",
    "    df_triples[\"subject\"] == df_object_properties[\"property_uri\"],\n",
    "    \"inner\"\n",
    ").select(\n",
    "    F.col(\"object\").alias(\"class_uri\"),\n",
    "    F.col(\"graph\")\n",
    ").distinct()\n",
    "\n",
    "# Filter out datatype URIs (XSD types, etc.)\n",
    "df_range_classes = df_range_classes.filter(\n",
    "    ~F.col(\"class_uri\").startswith(\"http://www.w3.org/2001/XMLSchema#\") &\n",
    "    ~F.col(\"class_uri\").startswith(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\") &\n",
    "    F.col(\"class_uri\").isNotNull()\n",
    ")\n",
    "\n",
    "print(f\"Found {df_range_classes.count()} classes from object property ranges\")\n",
    "\n",
    "# Step 3: Find classes from domain declarations of object properties\n",
    "df_domain_classes = df_triples.filter(\n",
    "    F.col(\"predicate\") == RDFS_DOMAIN\n",
    ").join(\n",
    "    df_object_properties, \n",
    "    df_triples[\"subject\"] == df_object_properties[\"property_uri\"],\n",
    "    \"inner\"\n",
    ").select(\n",
    "    F.col(\"object\").alias(\"class_uri\"),\n",
    "    F.col(\"graph\")\n",
    ").distinct()\n",
    "\n",
    "print(f\"Found {df_domain_classes.count()} classes from object property domains\")\n",
    "\n",
    "# Step 4: Combine all class sources\n",
    "df_classes = df_explicit_classes.union(df_range_classes).union(df_domain_classes).distinct()\n",
    "\n",
    "# Add class_type for compatibility (mark source)\n",
    "df_classes = df_classes.withColumn(\"class_type\", F.lit(OWL_CLASS))\n",
    "\n",
    "print(f\"\\n=== Total unique classes: {df_classes.count()} ===\")\n",
    "df_classes.show(10, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rdfs:subClassOf relationships\n",
    "df_subclass = df_triples.filter(\n",
    "    F.col(\"predicate\") == RDFS_SUBCLASS_OF\n",
    ").select(\n",
    "    F.col(\"subject\").alias(\"class_uri\"),\n",
    "    F.col(\"object\").alias(\"parent_class_uri\")\n",
    ")\n",
    "\n",
    "# Aggregate all parent classes for each class\n",
    "df_parents = df_subclass.groupBy(\"class_uri\").agg(\n",
    "    F.collect_set(\"parent_class_uri\").alias(\"parent_class_uris\")\n",
    ")\n",
    "\n",
    "print(f\"Found {df_subclass.count()} subClassOf relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rdfs:label for each class (prefer English or no language tag)\n",
    "df_labels = df_triples.filter(\n",
    "    (F.col(\"predicate\") == RDFS_LABEL) | (F.col(\"predicate\") == SKOS_PREFLABEL)\n",
    ").select(\n",
    "    F.col(\"subject\").alias(\"class_uri\"),\n",
    "    F.col(\"object\").alias(\"label\"),\n",
    "    F.col(\"lang\"),\n",
    "    F.col(\"predicate\").alias(\"label_predicate\")\n",
    ")\n",
    "\n",
    "# Rank labels: prefer English, then no language, then any\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df_labels = df_labels.withColumn(\n",
    "    \"lang_priority\",\n",
    "    F.when(F.col(\"lang\") == \"en\", 1)\n",
    "     .when(F.col(\"lang\").isNull(), 2)\n",
    "     .when(F.col(\"lang\") == \"\", 2)\n",
    "     .otherwise(3)\n",
    ")\n",
    "\n",
    "window = Window.partitionBy(\"class_uri\").orderBy(\"lang_priority\")\n",
    "df_best_labels = df_labels.withColumn(\"rank\", F.row_number().over(window)) \\\n",
    "    .filter(F.col(\"rank\") == 1) \\\n",
    "    .select(\"class_uri\", \"label\", \"lang\")\n",
    "\n",
    "print(f\"Found {df_best_labels.count()} classes with labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rdfs:comment / skos:definition for descriptions\n",
    "df_comments = df_triples.filter(\n",
    "    (F.col(\"predicate\") == RDFS_COMMENT) | (F.col(\"predicate\") == SKOS_DEFINITION)\n",
    ").select(\n",
    "    F.col(\"subject\").alias(\"class_uri\"),\n",
    "    F.col(\"object\").alias(\"description\"),\n",
    "    F.col(\"lang\").alias(\"desc_lang\")\n",
    ")\n",
    "\n",
    "# Prefer English descriptions\n",
    "df_comments = df_comments.withColumn(\n",
    "    \"lang_priority\",\n",
    "    F.when(F.col(\"desc_lang\") == \"en\", 1)\n",
    "     .when(F.col(\"desc_lang\").isNull(), 2)\n",
    "     .otherwise(3)\n",
    ")\n",
    "\n",
    "window = Window.partitionBy(\"class_uri\").orderBy(\"lang_priority\")\n",
    "df_best_descriptions = df_comments.withColumn(\"rank\", F.row_number().over(window)) \\\n",
    "    .filter(F.col(\"rank\") == 1) \\\n",
    "    .select(\"class_uri\", \"description\")\n",
    "\n",
    "print(f\"Found {df_best_descriptions.count()} classes with descriptions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e727089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all class information\n",
    "df_node_types = df_classes \\\n",
    "    .join(df_parents, \"class_uri\", \"left\") \\\n",
    "    .join(df_best_labels, \"class_uri\", \"left\") \\\n",
    "    .join(df_best_descriptions, \"class_uri\", \"left\")\n",
    "\n",
    "# Generate node type names\n",
    "df_node_types = df_node_types \\\n",
    "    .withColumn(\"local_name\", extract_local_name_udf(F.col(\"class_uri\"))) \\\n",
    "    .withColumn(\"node_type\", sanitize_name_udf(F.col(\"local_name\"))) \\\n",
    "    .withColumn(\"display_name\", F.coalesce(F.col(\"label\"), F.col(\"local_name\"))) \\\n",
    "    .withColumn(\"is_blank_node\", F.col(\"class_uri\").startswith(\"_:\"))\n",
    "\n",
    "# Generate parent node type names\n",
    "def extract_parent_types(parent_uris):\n",
    "    if parent_uris is None:\n",
    "        return None\n",
    "    return [sanitize_node_type_name(extract_local_name(uri)) for uri in parent_uris if uri]\n",
    "\n",
    "extract_parent_types_udf = F.udf(extract_parent_types, ArrayType(StringType()))\n",
    "\n",
    "df_node_types = df_node_types.withColumn(\n",
    "    \"parent_types\",\n",
    "    extract_parent_types_udf(F.col(\"parent_class_uris\"))\n",
    ")\n",
    "\n",
    "print(f\"Generated {df_node_types.count()} node type mappings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fffdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select final columns for output\n",
    "df_output = df_node_types.select(\n",
    "    \"class_uri\",\n",
    "    \"node_type\",\n",
    "    \"display_name\",\n",
    "    \"description\",\n",
    "    \"parent_class_uris\",\n",
    "    \"parent_types\",\n",
    "    \"class_type\",\n",
    "    \"is_blank_node\",\n",
    "    \"graph\"\n",
    ")\n",
    "\n",
    "print(\"\\nNode Type Mapping Preview:\")\n",
    "df_output.select(\"node_type\", \"display_name\", \"parent_types\", \"class_uri\") \\\n",
    "    .orderBy(\"node_type\") \\\n",
    "    .show(20, truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show class hierarchy\n",
    "print(\"\\nClass Hierarchy (classes with parents):\")\n",
    "df_output.filter(F.size(F.col(\"parent_types\")) > 0) \\\n",
    "    .select(\"node_type\", \"parent_types\") \\\n",
    "    .orderBy(\"node_type\") \\\n",
    "    .show(30, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992905db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate node type names (check for duplicates and invalid names)\n",
    "print(\"\\nValidation:\")\n",
    "\n",
    "# Check for duplicate node type names (same name from different URIs)\n",
    "df_duplicates = df_output.groupBy(\"node_type\").agg(\n",
    "    F.count(\"*\").alias(\"count\"),\n",
    "    F.collect_list(\"class_uri\").alias(\"uris\")\n",
    ").filter(F.col(\"count\") > 1)\n",
    "\n",
    "dup_count = df_duplicates.count()\n",
    "if dup_count > 0:\n",
    "    print(f\"WARNING: {dup_count} duplicate node type names found:\")\n",
    "    df_duplicates.show(10, truncate=80)\n",
    "else:\n",
    "    print(\"[OK] No duplicate node type names\")\n",
    "\n",
    "# Check for blank nodes\n",
    "blank_count = df_output.filter(F.col(\"is_blank_node\") == True).count()\n",
    "if blank_count > 0:\n",
    "    print(f\"INFO: {blank_count} blank node classes found (stable IDs generated)\")\n",
    "else:\n",
    "    print(\"[OK] No blank node classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLASS DISCOVERY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_types = df_output.count()\n",
    "with_parents = df_output.filter(F.size(F.col(\"parent_types\")) > 0).count()\n",
    "with_labels = df_output.filter(F.col(\"display_name\").isNotNull()).count()\n",
    "with_descriptions = df_output.filter(F.col(\"description\").isNotNull()).count()\n",
    "\n",
    "print(f\"\\nTotal node types discovered: {total_types}\")\n",
    "print(f\"\\nClass Sources:\")\n",
    "print(f\"  - Explicit declarations (owl:Class/rdfs:Class): {df_explicit_classes.count()}\")\n",
    "print(f\"  - From object property ranges: {df_range_classes.count()}\")\n",
    "print(f\"  - From object property domains: {df_domain_classes.count()}\")\n",
    "\n",
    "print(f\"\\nMetadata Coverage:\")\n",
    "print(f\"  - With class hierarchy: {with_parents} ({100*with_parents//total_types if total_types else 0}%)\")\n",
    "print(f\"  - With display names: {with_labels} ({100*with_labels//total_types if total_types else 0}%)\")\n",
    "print(f\"  - With descriptions: {with_descriptions} ({100*with_descriptions//total_types if total_types else 0}%)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA QUALITY NOTE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "Classes are discovered from multiple sources to ensure completeness:\n",
    "1. Explicit declarations - classes typed as owl:Class or rdfs:Class\n",
    "2. Property ranges - classes referenced as targets of object properties\n",
    "3. Property domains - classes referenced as sources of object properties\n",
    "\n",
    "This ensures that when relationships are created in the Ontology, \n",
    "both source and target entity types exist.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Delta table\n",
    "df_output.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(OUTPUT_TABLE)\n",
    "\n",
    "print(f\"\\nSaved {total_types} node types to '{OUTPUT_TABLE}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as JSON for frontend/API consumption\n",
    "node_types_json = [\n",
    "    {\n",
    "        \"node_type\": row.node_type,\n",
    "        \"display_name\": row.display_name,\n",
    "        \"description\": row.description,\n",
    "        \"parent_types\": row.parent_types or [],\n",
    "        \"class_uri\": row.class_uri,\n",
    "        \"is_blank_node\": row.is_blank_node,\n",
    "    }\n",
    "    for row in df_output.collect()\n",
    "]\n",
    "\n",
    "print(\"\\nJSON output sample (first 3):\")\n",
    "print(json.dumps(node_types_json[:3], indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
