{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2597afe1",
   "metadata": {},
   "source": [
    "# 05 - Instance Data Translator\n",
    "\n",
    "Translates RDF instance data to node and edge records.\n",
    "\n",
    "**Input**:\n",
    "- `bronze_triples` - Raw RDF triples\n",
    "- `silver_node_types` - Node type definitions (from F4.1)\n",
    "- `silver_properties` - Property mappings (from F4.2)\n",
    "\n",
    "**Output**:\n",
    "- `silver_nodes` - Node records with properties\n",
    "- `silver_edges` - Edge records linking nodes\n",
    "\n",
    "## Translation Rules\n",
    "\n",
    "| RDF Pattern | LPG Output |\n",
    "|-------------|------------|\n",
    "| Subject with rdf:type | Node with labels |\n",
    "| DatatypeProperty triple | Node property |\n",
    "| ObjectProperty triple | Edge record |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_TRIPLES = \"bronze_triples\"\n",
    "INPUT_NODE_TYPES = \"silver_node_types\"\n",
    "INPUT_PROPERTIES = \"silver_properties\"\n",
    "OUTPUT_NODES = \"silver_nodes\"\n",
    "OUTPUT_EDGES = \"silver_edges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, ArrayType, MapType, BooleanType\n",
    "from pyspark.sql.window import Window\n",
    "import re\n",
    "import hashlib\n",
    "\n",
    "# RDF namespace constants\n",
    "RDF_TYPE = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"\n",
    "RDFS_LABEL = \"http://www.w3.org/2000/01/rdf-schema#label\"\n",
    "SKOS_PREFLABEL = \"http://www.w3.org/2004/02/skos/core#prefLabel\"\n",
    "\n",
    "# Schema predicate URIs to exclude from instance data\n",
    "SCHEMA_PREDICATES = {\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#subClassOf\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#domain\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#range\",\n",
    "    \"http://www.w3.org/2002/07/owl#equivalentClass\",\n",
    "    \"http://www.w3.org/2002/07/owl#disjointWith\",\n",
    "    \"http://www.w3.org/2002/07/owl#inverseOf\",\n",
    "}\n",
    "\n",
    "# Schema type URIs (subjects with these types are schema, not instances)\n",
    "SCHEMA_TYPES = {\n",
    "    \"http://www.w3.org/2002/07/owl#Class\",\n",
    "    \"http://www.w3.org/2002/07/owl#ObjectProperty\",\n",
    "    \"http://www.w3.org/2002/07/owl#DatatypeProperty\",\n",
    "    \"http://www.w3.org/2002/07/owl#AnnotationProperty\",\n",
    "    \"http://www.w3.org/2002/07/owl#Ontology\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#Class\",\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#Property\",\n",
    "    \"http://www.w3.org/ns/shacl#NodeShape\",\n",
    "    \"http://www.w3.org/ns/shacl#PropertyShape\",\n",
    "}\n",
    "\n",
    "def extract_local_name(uri: str) -> str:\n",
    "    \"\"\"Extract local name from URI.\"\"\"\n",
    "    if uri is None:\n",
    "        return None\n",
    "    if uri.startswith(\"_:\"):\n",
    "        return uri[2:]\n",
    "    if \"#\" in uri:\n",
    "        return uri.split(\"#\")[-1]\n",
    "    if \"/\" in uri:\n",
    "        return uri.split(\"/\")[-1]\n",
    "    return uri\n",
    "\n",
    "def generate_node_id(uri: str, graph: str) -> str:\n",
    "    \"\"\"Generate stable node ID from URI.\"\"\"\n",
    "    if uri is None:\n",
    "        return None\n",
    "    if uri.startswith(\"_:\"):\n",
    "        # Blank node - create stable hash using graph context\n",
    "        combined = f\"{graph}:{uri}\"\n",
    "        return \"blank_\" + hashlib.md5(combined.encode()).hexdigest()[:12]\n",
    "    # Named node - use local name or hash of full URI\n",
    "    local = extract_local_name(uri)\n",
    "    if local and len(local) <= 50:\n",
    "        return local\n",
    "    return hashlib.md5(uri.encode()).hexdigest()[:16]\n",
    "\n",
    "def sanitize_property_name(name: str) -> str:\n",
    "    \"\"\"Convert property name to camelCase identifier.\"\"\"\n",
    "    if name is None:\n",
    "        return None\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9]', ' ', name)\n",
    "    words = cleaned.split()\n",
    "    if not words:\n",
    "        return \"unknownProperty\"\n",
    "    result = words[0].lower() + ''.join(w.capitalize() for w in words[1:])\n",
    "    if result and not result[0].isalpha():\n",
    "        result = \"p\" + result\n",
    "    return result\n",
    "\n",
    "extract_local_name_udf = F.udf(extract_local_name, StringType())\n",
    "generate_node_id_udf = F.udf(generate_node_id, StringType())\n",
    "sanitize_property_name_udf = F.udf(sanitize_property_name, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input tables\n",
    "df_triples = spark.table(INPUT_TRIPLES)\n",
    "print(f\"Loaded {df_triples.count()} triples from '{INPUT_TRIPLES}'\")\n",
    "\n",
    "# Load node types for label mapping\n",
    "df_node_types = spark.table(INPUT_NODE_TYPES)\n",
    "print(f\"Loaded {df_node_types.count()} node types from '{INPUT_NODE_TYPES}'\")\n",
    "\n",
    "# Load property mappings\n",
    "df_properties = spark.table(INPUT_PROPERTIES)\n",
    "print(f\"Loaded {df_properties.count()} properties from '{INPUT_PROPERTIES}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a983b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify schema subjects (things that ARE classes/properties, not instances)\n",
    "df_schema_subjects = df_triples.filter(\n",
    "    (F.col(\"predicate\") == RDF_TYPE) & \n",
    "    (F.col(\"object\").isin(list(SCHEMA_TYPES)))\n",
    ").select(\"subject\").distinct()\n",
    "\n",
    "schema_subjects = set(row.subject for row in df_schema_subjects.collect())\n",
    "print(f\"Found {len(schema_subjects)} schema subjects to exclude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to instance triples only (exclude schema definitions)\n",
    "df_instance_triples = df_triples.filter(\n",
    "    ~F.col(\"subject\").isin(schema_subjects) &\n",
    "    ~F.col(\"predicate\").isin(list(SCHEMA_PREDICATES))\n",
    ")\n",
    "\n",
    "print(f\"Instance triples: {df_instance_triples.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b832e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique instance subjects (potential nodes)\n",
    "df_subjects = df_instance_triples.select(\n",
    "    F.col(\"subject\").alias(\"uri\"),\n",
    "    F.col(\"graph\")\n",
    ").distinct()\n",
    "\n",
    "# Generate node IDs\n",
    "df_subjects = df_subjects.withColumn(\n",
    "    \"node_id\",\n",
    "    generate_node_id_udf(F.col(\"uri\"), F.col(\"graph\"))\n",
    ")\n",
    "\n",
    "print(f\"Found {df_subjects.count()} unique instance subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rdf:type declarations for instances → node labels\n",
    "df_types = df_instance_triples.filter(\n",
    "    F.col(\"predicate\") == RDF_TYPE\n",
    ").select(\n",
    "    F.col(\"subject\").alias(\"uri\"),\n",
    "    F.col(\"object\").alias(\"type_uri\"),\n",
    "    F.col(\"graph\")\n",
    ")\n",
    "\n",
    "# Join with node_types to get the label name\n",
    "df_types_labeled = df_types.join(\n",
    "    df_node_types.select(\n",
    "        F.col(\"class_uri\").alias(\"type_uri\"),\n",
    "        F.col(\"node_type\").alias(\"label\")\n",
    "    ),\n",
    "    \"type_uri\",\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# For types not in our node_types table, extract local name\n",
    "df_types_labeled = df_types_labeled.withColumn(\n",
    "    \"label\",\n",
    "    F.coalesce(F.col(\"label\"), extract_local_name_udf(F.col(\"type_uri\")))\n",
    ")\n",
    "\n",
    "# Aggregate all labels per node\n",
    "df_node_labels = df_types_labeled.groupBy(\"uri\", \"graph\").agg(\n",
    "    F.collect_set(\"label\").alias(\"labels\"),\n",
    "    F.collect_set(\"type_uri\").alias(\"type_uris\")\n",
    ")\n",
    "\n",
    "print(f\"Nodes with type declarations: {df_node_labels.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get property mapping info (which predicates are node props vs edges)\n",
    "node_prop_predicates = set(\n",
    "    row.property_uri for row in \n",
    "    df_properties.filter(F.col(\"mapping_type\") == \"node_property\").collect()\n",
    ")\n",
    "edge_predicates = set(\n",
    "    row.property_uri for row in \n",
    "    df_properties.filter(F.col(\"mapping_type\") == \"edge\").collect()\n",
    ")\n",
    "\n",
    "print(f\"Node property predicates: {len(node_prop_predicates)}\")\n",
    "print(f\"Edge predicates: {len(edge_predicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50022792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract node properties (datatype property triples)\n",
    "# Include rdfs:label, skos:prefLabel, and mapped DatatypeProperties\n",
    "label_predicates = [RDFS_LABEL, SKOS_PREFLABEL]\n",
    "all_node_prop_predicates = node_prop_predicates.union(set(label_predicates))\n",
    "\n",
    "df_node_props = df_instance_triples.filter(\n",
    "    (F.col(\"predicate\").isin(list(all_node_prop_predicates))) |\n",
    "    (F.col(\"object_type\") == \"literal\")  # All literals are node properties\n",
    ").filter(\n",
    "    F.col(\"predicate\") != RDF_TYPE  # Exclude type triples\n",
    ")\n",
    "\n",
    "print(f\"Node property triples: {df_node_props.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare property values with names\n",
    "df_node_props = df_node_props.withColumn(\n",
    "    \"property_name\",\n",
    "    sanitize_property_name_udf(extract_local_name_udf(F.col(\"predicate\")))\n",
    ")\n",
    "\n",
    "# Handle multi-valued properties by collecting into arrays\n",
    "# Group by subject and property name\n",
    "df_props_grouped = df_node_props.groupBy(\"subject\", \"graph\", \"property_name\").agg(\n",
    "    F.collect_list(\"object\").alias(\"values\"),\n",
    "    F.first(\"datatype\").alias(\"datatype\"),\n",
    "    F.first(\"lang\").alias(\"lang\")\n",
    ")\n",
    "\n",
    "# For single-valued properties, unwrap from array\n",
    "df_props_grouped = df_props_grouped.withColumn(\n",
    "    \"value\",\n",
    "    F.when(F.size(\"values\") == 1, F.col(\"values\")[0]).otherwise(F.to_json(F.col(\"values\")))\n",
    ")\n",
    "\n",
    "df_props_grouped.show(5, truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot properties to create property map per node\n",
    "df_props_pivot = df_props_grouped.groupBy(\"subject\", \"graph\").pivot(\"property_name\").agg(\n",
    "    F.first(\"value\")\n",
    ")\n",
    "\n",
    "# Get all property columns (everything except subject and graph)\n",
    "prop_cols = [c for c in df_props_pivot.columns if c not in [\"subject\", \"graph\"]]\n",
    "print(f\"Property columns extracted: {len(prop_cols)}\")\n",
    "\n",
    "# Create properties map column\n",
    "df_props_map = df_props_pivot.withColumn(\n",
    "    \"properties\",\n",
    "    F.create_map(\n",
    "        *[item for col in prop_cols for item in (F.lit(col), F.col(col))]\n",
    "    ) if prop_cols else F.lit(None).cast(MapType(StringType(), StringType()))\n",
    ")\n",
    "\n",
    "# Filter out null values from map\n",
    "if prop_cols:\n",
    "    df_props_map = df_props_map.withColumn(\n",
    "        \"properties\",\n",
    "        F.expr(\"map_filter(properties, (k, v) -> v IS NOT NULL)\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7232b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final nodes table\n",
    "df_nodes = df_subjects.alias(\"s\").join(\n",
    "    df_node_labels.alias(\"l\"),\n",
    "    (F.col(\"s.uri\") == F.col(\"l.uri\")) & (F.col(\"s.graph\") == F.col(\"l.graph\")),\n",
    "    \"left\"\n",
    ").join(\n",
    "    df_props_map.select(\"subject\", \"graph\", \"properties\").alias(\"p\"),\n",
    "    (F.col(\"s.uri\") == F.col(\"p.subject\")) & (F.col(\"s.graph\") == F.col(\"p.graph\")),\n",
    "    \"left\"\n",
    ").select(\n",
    "    F.col(\"s.node_id\").alias(\"id\"),\n",
    "    F.col(\"s.uri\"),\n",
    "    F.coalesce(F.col(\"l.labels\"), F.array(F.lit(\"Entity\"))).alias(\"labels\"),\n",
    "    F.col(\"l.type_uris\"),\n",
    "    F.col(\"p.properties\"),\n",
    "    F.col(\"s.uri\").startswith(\"_:\").alias(\"is_blank_node\"),\n",
    "    F.col(\"s.graph\").alias(\"source_graph\")\n",
    ")\n",
    "\n",
    "# Add display name from properties (prefer label > prefLabel > id)\n",
    "df_nodes = df_nodes.withColumn(\n",
    "    \"display_name\",\n",
    "    F.coalesce(\n",
    "        F.col(\"properties\")[\"label\"],\n",
    "        F.col(\"properties\")[\"prefLabel\"],\n",
    "        F.col(\"id\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Total nodes: {df_nodes.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b1f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample nodes\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE NODES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_nodes.select(\"id\", \"display_name\", \"labels\", \"source_graph\").show(15, truncate=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show nodes with properties\n",
    "print(\"\\nSample node properties:\")\n",
    "df_nodes.filter(F.col(\"properties\").isNotNull()).select(\n",
    "    \"id\", \"labels\", \"properties\"\n",
    ").show(10, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build node ID lookup for edge creation\n",
    "node_id_map = df_subjects.select(\"uri\", \"node_id\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe905a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract edges (object property triples)\n",
    "# An edge connects subject → object where both are URIs (not literals)\n",
    "df_edge_triples = df_instance_triples.filter(\n",
    "    (F.col(\"object_type\") == \"uri\") &\n",
    "    (F.col(\"predicate\") != RDF_TYPE) &\n",
    "    (~F.col(\"predicate\").isin(list(SCHEMA_PREDICATES)))\n",
    ")\n",
    "\n",
    "print(f\"Edge candidate triples: {df_edge_triples.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cf560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build edges with source and target IDs\n",
    "df_edges = df_edge_triples.alias(\"e\").join(\n",
    "    node_id_map.alias(\"src\"),\n",
    "    F.col(\"e.subject\") == F.col(\"src.uri\"),\n",
    "    \"inner\"\n",
    ").join(\n",
    "    node_id_map.alias(\"tgt\"),\n",
    "    F.col(\"e.object\") == F.col(\"tgt.uri\"),\n",
    "    \"inner\"\n",
    ").select(\n",
    "    F.col(\"src.node_id\").alias(\"source_id\"),\n",
    "    F.col(\"tgt.node_id\").alias(\"target_id\"),\n",
    "    sanitize_property_name_udf(extract_local_name_udf(F.col(\"e.predicate\"))).alias(\"type\"),\n",
    "    F.col(\"e.predicate\").alias(\"predicate_uri\"),\n",
    "    F.col(\"e.subject\").alias(\"source_uri\"),\n",
    "    F.col(\"e.object\").alias(\"target_uri\"),\n",
    "    F.col(\"e.graph\").alias(\"source_graph\")\n",
    ")\n",
    "\n",
    "# Generate stable edge ID\n",
    "df_edges = df_edges.withColumn(\n",
    "    \"id\",\n",
    "    F.concat(\n",
    "        F.col(\"source_id\"),\n",
    "        F.lit(\"_\"),\n",
    "        F.col(\"type\"),\n",
    "        F.lit(\"_\"),\n",
    "        F.col(\"target_id\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Total edges: {df_edges.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0610749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample edges\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE EDGES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_edges.select(\"source_id\", \"type\", \"target_id\", \"source_graph\").show(15, truncate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b94c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge type distribution\n",
    "print(\"\\nEdge type distribution:\")\n",
    "df_edges.groupBy(\"type\").count().orderBy(F.desc(\"count\")).show(20, truncate=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for orphan edges (edges to nodes not in our node set)\n",
    "node_ids = set(row.id for row in df_nodes.select(\"id\").distinct().collect())\n",
    "edge_source_ids = set(row.source_id for row in df_edges.select(\"source_id\").distinct().collect())\n",
    "edge_target_ids = set(row.target_id for row in df_edges.select(\"target_id\").distinct().collect())\n",
    "\n",
    "orphan_sources = edge_source_ids - node_ids\n",
    "orphan_targets = edge_target_ids - node_ids\n",
    "\n",
    "if orphan_sources:\n",
    "    print(f\"WARNING: {len(orphan_sources)} edges have source IDs not in nodes\")\n",
    "else:\n",
    "    print(\"[OK] All edge sources exist in nodes\")\n",
    "\n",
    "if orphan_targets:\n",
    "    print(f\"WARNING: {len(orphan_targets)} edges have target IDs not in nodes\")\n",
    "else:\n",
    "    print(\"[OK] All edge targets exist in nodes\")\n",
    "\n",
    "# Check for duplicate node IDs\n",
    "dup_nodes = df_nodes.groupBy(\"id\").count().filter(F.col(\"count\") > 1)\n",
    "if dup_nodes.count() > 0:\n",
    "    print(f\"WARNING: {dup_nodes.count()} duplicate node IDs\")\n",
    "    dup_nodes.show(5)\n",
    "else:\n",
    "    print(\"[OK] No duplicate node IDs\")\n",
    "\n",
    "# Check blank nodes\n",
    "blank_count = df_nodes.filter(F.col(\"is_blank_node\") == True).count()\n",
    "print(f\"\\nBlank nodes: {blank_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b814d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_nodes = df_nodes.count()\n",
    "total_edges = df_edges.count()\n",
    "nodes_with_props = df_nodes.filter(F.size(\"properties\") > 0).count()\n",
    "nodes_with_labels = df_nodes.filter(F.size(\"labels\") > 0).count()\n",
    "unique_labels = df_nodes.select(F.explode(\"labels\").alias(\"label\")).distinct().count()\n",
    "unique_edge_types = df_edges.select(\"type\").distinct().count()\n",
    "\n",
    "print(f\"\\nNodes: {total_nodes}\")\n",
    "print(f\"  - With properties: {nodes_with_props}\")\n",
    "print(f\"  - With labels: {nodes_with_labels}\")\n",
    "print(f\"  - Unique label types: {unique_labels}\")\n",
    "print(f\"\\nEdges: {total_edges}\")\n",
    "print(f\"  - Unique edge types: {unique_edge_types}\")\n",
    "\n",
    "# Per-graph breakdown\n",
    "print(\"\\nPer-graph breakdown:\")\n",
    "df_nodes.groupBy(\"source_graph\").count().withColumnRenamed(\"count\", \"nodes\").join(\n",
    "    df_edges.groupBy(\"source_graph\").count().withColumnRenamed(\"count\", \"edges\"),\n",
    "    \"source_graph\",\n",
    "    \"outer\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2858263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save nodes to Delta table\n",
    "df_nodes.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(OUTPUT_NODES)\n",
    "\n",
    "print(f\"Saved {total_nodes} nodes to '{OUTPUT_NODES}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save edges to Delta table\n",
    "df_edges.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(OUTPUT_EDGES)\n",
    "\n",
    "print(f\"Saved {total_edges} edges to '{OUTPUT_EDGES}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65555b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INSTANCE TRANSLATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOutput tables:\")\n",
    "print(f\"  - {OUTPUT_NODES}: {total_nodes} nodes\")\n",
    "print(f\"  - {OUTPUT_EDGES}: {total_edges} edges\")\n",
    "print(f\"\\nNext: Run 06_graph_builder to generate Graph Model JSON\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
