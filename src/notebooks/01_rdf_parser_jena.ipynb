{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4afed6",
   "metadata": {},
   "source": [
    "# 01 - RDF Parser (Apache Jena)\n",
    "\n",
    "Parses Turtle (.ttl) RDF files into bronze layer Delta table using Apache Jena.\n",
    "\n",
    "**Prerequisites**: Attach Fabric Environment `env_rdf_jena` with `jena-shaded-4.10.0.jar`  \n",
    "(Built from `tools/jena-shaded/` - single uber JAR with relocated dependencies)\n",
    "\n",
    "**Input**: TTL files from lakehouse Files (shortcuts or uploaded)  \n",
    "**Output**: Delta table `bronze_triples`\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| subject | String | Subject URI or blank node |\n",
    "| predicate | String | Predicate URI |\n",
    "| object | String | Object value (URI, blank node, or literal) |\n",
    "| object_type | String | 'uri', 'bnode', or 'literal' |\n",
    "| datatype | String | XSD datatype for literals (nullable) |\n",
    "| lang | String | Language tag for literals (nullable) |\n",
    "| graph | String | Source graph/file name |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d759441f",
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "// Configuration\n",
    "val lakehousePath = \"/lakehouse/default/Files\"\n",
    "\n",
    "// Input folders - load BOTH schema (normative) AND instance data (examples)\n",
    "// Schema files contain class definitions, descriptions, labels\n",
    "// Example files contain instance data\n",
    "val inputFolders = Seq(\n",
    "  \"normative_nen2660\",   // Schema with descriptions (nen2660-term.ttl, nen2660-rdfs.ttl, etc.)\n",
    "  \"examples_nen2660\"     // Instance data (IJsselbrug.ttl, etc.)\n",
    ")\n",
    "\n",
    "val outputTable = \"bronze_triples\"\n",
    "\n",
    "println(s\"Will parse TTL files from: ${inputFolders.mkString(\", \")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1720f",
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.jena.riot.RDFDataMgr\n",
    "import org.apache.jena.riot.Lang\n",
    "import org.apache.jena.graph.{Node, Triple}\n",
    "import org.apache.spark.sql.{Row, SparkSession}\n",
    "import org.apache.spark.sql.types._\n",
    "import scala.collection.JavaConverters._\n",
    "import java.io.File\n",
    "\n",
    "// Triple schema for bronze layer\n",
    "val tripleSchema = StructType(Seq(\n",
    "  StructField(\"subject\", StringType, nullable = false),\n",
    "  StructField(\"predicate\", StringType, nullable = false),\n",
    "  StructField(\"object\", StringType, nullable = false),\n",
    "  StructField(\"object_type\", StringType, nullable = false),\n",
    "  StructField(\"datatype\", StringType, nullable = true),\n",
    "  StructField(\"lang\", StringType, nullable = true),\n",
    "  StructField(\"graph\", StringType, nullable = false)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c170225",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Extract string representation and metadata from a Jena Node\n",
    " */\n",
    "def extractNode(node: Node): (String, String, Option[String], Option[String]) = {\n",
    "  if (node.isURI) {\n",
    "    (node.getURI, \"uri\", None, None)\n",
    "  } else if (node.isBlank) {\n",
    "    (s\"_:${node.getBlankNodeLabel}\", \"bnode\", None, None)\n",
    "  } else if (node.isLiteral) {\n",
    "    val value = node.getLiteralLexicalForm\n",
    "    val datatype = Option(node.getLiteralDatatypeURI)\n",
    "    val lang = Option(node.getLiteralLanguage).filter(_.nonEmpty)\n",
    "    (value, \"literal\", datatype, lang)\n",
    "  } else {\n",
    "    (node.toString, \"unknown\", None, None)\n",
    "  }\n",
    "}\n",
    "\n",
    "/**\n",
    " * Parse a TTL file using Apache Jena and return triples as Rows\n",
    " */\n",
    "def parseTtlFile(filePath: String, graphName: String): Seq[Row] = {\n",
    "  val model = RDFDataMgr.loadModel(filePath, Lang.TURTLE)\n",
    "  val graph = model.getGraph\n",
    "  \n",
    "  graph.find().asScala.map { triple =>\n",
    "    val (subj, _, _, _) = extractNode(triple.getSubject)\n",
    "    val pred = triple.getPredicate.getURI\n",
    "    val (obj, objType, datatype, lang) = extractNode(triple.getObject)\n",
    "    \n",
    "    Row(subj, pred, obj, objType, datatype.orNull, lang.orNull, graphName)\n",
    "  }.toSeq\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Discover TTL files in all input folders\n",
    "def findTtlFiles(dir: File): Seq[File] = {\n",
    "  if (dir.isDirectory) {\n",
    "    dir.listFiles.flatMap { f =>\n",
    "      if (f.isDirectory) findTtlFiles(f)\n",
    "      else if (f.getName.endsWith(\".ttl\")) Seq(f)\n",
    "      else Seq.empty\n",
    "    }.toSeq\n",
    "  } else Seq.empty\n",
    "}\n",
    "\n",
    "// Collect files from all input folders\n",
    "val ttlFiles = inputFolders.flatMap { folder =>\n",
    "  val inputPath = s\"$lakehousePath/$folder\"\n",
    "  val inputDir = new File(inputPath)\n",
    "  println(s\"\\nScanning folder: $folder\")\n",
    "  val files = findTtlFiles(inputDir)\n",
    "  println(s\"  Found ${files.length} TTL files\")\n",
    "  files.foreach(f => println(s\"    - ${f.getName}\"))\n",
    "  files\n",
    "}\n",
    "\n",
    "println(s\"\\n=== Total: ${ttlFiles.length} TTL files from ${inputFolders.length} folders ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca949f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Parse all TTL files\n",
    "val allTriples = ttlFiles.flatMap { file =>\n",
    "  val graphName = file.getName.stripSuffix(\".ttl\")\n",
    "  println(s\"Parsing: ${file.getName}\")\n",
    "  val triples = parseTtlFile(file.getAbsolutePath, graphName)\n",
    "  println(s\"  -> ${triples.length} triples\")\n",
    "  triples\n",
    "}\n",
    "\n",
    "println(s\"\\nTotal triples: ${allTriples.length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create DataFrame and show sample\n",
    "val dfTriples = spark.createDataFrame(\n",
    "  spark.sparkContext.parallelize(allTriples),\n",
    "  tripleSchema\n",
    ")\n",
    "\n",
    "dfTriples.show(10, truncate = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efa57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Write to Delta table\n",
    "dfTriples.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"overwriteSchema\", \"true\")\n",
    "  .saveAsTable(outputTable)\n",
    "\n",
    "println(s\"Saved ${dfTriples.count()} triples to table '$outputTable'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Verification: show stats per graph\n",
    "spark.sql(s\"\"\"\n",
    "  SELECT graph, \n",
    "         COUNT(*) as triple_count,\n",
    "         COUNT(DISTINCT subject) as unique_subjects,\n",
    "         COUNT(DISTINCT predicate) as unique_predicates\n",
    "  FROM $outputTable\n",
    "  GROUP BY graph\n",
    "  ORDER BY triple_count DESC\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
