{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa1b6dc",
   "metadata": {},
   "source": [
    "# 02 - Schema Richness Detector\n",
    "\n",
    "Analyzes RDF data to detect schema richness level (0-4) for adaptive guidance.\n",
    "\n",
    "**Input**: `bronze_triples` Delta table (from 01_rdf_parser_jena)\n",
    "**Output**: Schema level, confidence, detected constructs, and recommendations\n",
    "\n",
    "## Schema Levels\n",
    "\n",
    "| Level | Name | Key Indicators |\n",
    "|-------|------|----------------|\n",
    "| 0 | No Schema | Only rdf:type, no class/property definitions |\n",
    "| 1 | SKOS Terms | skos:Concept, skos:prefLabel, skos:broader |\n",
    "| 2 | RDFS Classes | rdfs:Class, rdfs:subClassOf, rdfs:domain, rdfs:range |\n",
    "| 3 | OWL Ontology | owl:Class, owl:ObjectProperty, owl:DatatypeProperty |\n",
    "| 4 | SHACL Shapes | sh:NodeShape, sh:PropertyShape, sh:path |\n",
    "\n",
    "Detection is progressive: Level 4 includes all lower-level constructs.\n",
    "\n",
    "## Additional Analysis\n",
    "\n",
    "- **owl:imports detection** - Identifies referenced ontologies that could be loaded\n",
    "- **Graph classification** - Categorizes each graph as `schema`, `instance`, or `mixed`\n",
    "- **Recommendations** - Suggests loading informative/normative schemas when beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb2af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_TABLE = \"bronze_triples\"\n",
    "OUTPUT_TABLE = \"bronze_schema_analysis\"  # Optional: persist results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "import json\n",
    "\n",
    "# Schema construct indicators by level\n",
    "SCHEMA_INDICATORS = {\n",
    "    # Level 4: SHACL (highest priority - check first)\n",
    "    4: {\n",
    "        \"name\": \"SHACL Shapes\",\n",
    "        \"predicates\": [\n",
    "            \"http://www.w3.org/ns/shacl#NodeShape\",\n",
    "            \"http://www.w3.org/ns/shacl#PropertyShape\",\n",
    "            \"http://www.w3.org/ns/shacl#path\",\n",
    "            \"http://www.w3.org/ns/shacl#targetClass\",\n",
    "            \"http://www.w3.org/ns/shacl#property\",\n",
    "            \"http://www.w3.org/ns/shacl#datatype\",\n",
    "            \"http://www.w3.org/ns/shacl#minCount\",\n",
    "            \"http://www.w3.org/ns/shacl#maxCount\",\n",
    "        ],\n",
    "        \"types\": [\n",
    "            \"http://www.w3.org/ns/shacl#NodeShape\",\n",
    "            \"http://www.w3.org/ns/shacl#PropertyShape\",\n",
    "        ]\n",
    "    },\n",
    "    # Level 3: OWL\n",
    "    3: {\n",
    "        \"name\": \"OWL Ontology\",\n",
    "        \"predicates\": [\n",
    "            \"http://www.w3.org/2002/07/owl#equivalentClass\",\n",
    "            \"http://www.w3.org/2002/07/owl#disjointWith\",\n",
    "            \"http://www.w3.org/2002/07/owl#inverseOf\",\n",
    "            \"http://www.w3.org/2002/07/owl#unionOf\",\n",
    "            \"http://www.w3.org/2002/07/owl#intersectionOf\",\n",
    "            \"http://www.w3.org/2002/07/owl#onProperty\",\n",
    "            \"http://www.w3.org/2002/07/owl#someValuesFrom\",\n",
    "            \"http://www.w3.org/2002/07/owl#allValuesFrom\",\n",
    "            \"http://www.w3.org/2002/07/owl#cardinality\",\n",
    "        ],\n",
    "        \"types\": [\n",
    "            \"http://www.w3.org/2002/07/owl#Class\",\n",
    "            \"http://www.w3.org/2002/07/owl#ObjectProperty\",\n",
    "            \"http://www.w3.org/2002/07/owl#DatatypeProperty\",\n",
    "            \"http://www.w3.org/2002/07/owl#AnnotationProperty\",\n",
    "            \"http://www.w3.org/2002/07/owl#Ontology\",\n",
    "            \"http://www.w3.org/2002/07/owl#Restriction\",\n",
    "        ]\n",
    "    },\n",
    "    # Level 2: RDFS\n",
    "    2: {\n",
    "        \"name\": \"RDFS Schema\",\n",
    "        \"predicates\": [\n",
    "            \"http://www.w3.org/2000/01/rdf-schema#subClassOf\",\n",
    "            \"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\",\n",
    "            \"http://www.w3.org/2000/01/rdf-schema#domain\",\n",
    "            \"http://www.w3.org/2000/01/rdf-schema#range\",\n",
    "            \"http://www.w3.org/2000/01/rdf-schema#label\",\n",
    "            \"http://www.w3.org/2000/01/rdf-schema#comment\",\n",
    "        ],\n",
    "        \"types\": [\n",
    "            \"http://www.w3.org/2000/01/rdf-schema#Class\",\n",
    "            \"http://www.w3.org/1999/02/22-rdf-syntax-ns#Property\",\n",
    "        ]\n",
    "    },\n",
    "    # Level 1: SKOS\n",
    "    1: {\n",
    "        \"name\": \"SKOS Vocabulary\",\n",
    "        \"predicates\": [\n",
    "            \"http://www.w3.org/2004/02/skos/core#prefLabel\",\n",
    "            \"http://www.w3.org/2004/02/skos/core#altLabel\",\n",
    "            \"http://www.w3.org/2004/02/skos/core#definition\",\n",
    "            \"http://www.w3.org/2004/02/skos/core#broader\",\n",
    "            \"http://www.w3.org/2004/02/skos/core#narrower\",\n",
    "            \"http://www.w3.org/2004/02/skos/core#related\",\n",
    "            \"http://www.w3.org/2004/02/skos/core#inScheme\",\n",
    "        ],\n",
    "        \"types\": [\n",
    "            \"http://www.w3.org/2004/02/skos/core#Concept\",\n",
    "            \"http://www.w3.org/2004/02/skos/core#ConceptScheme\",\n",
    "            \"http://www.w3.org/2004/02/skos/core#Collection\",\n",
    "        ]\n",
    "    },\n",
    "    # Level 0: Instance data only\n",
    "    0: {\n",
    "        \"name\": \"Instance Data Only\",\n",
    "        \"predicates\": [\n",
    "            \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\",\n",
    "        ],\n",
    "        \"types\": []  # Any types that aren't schema types\n",
    "    }\n",
    "}\n",
    "\n",
    "# Common namespace prefixes for display\n",
    "PREFIXES = {\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\": \"rdf:\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#\": \"rdfs:\",\n",
    "    \"http://www.w3.org/2002/07/owl#\": \"owl:\",\n",
    "    \"http://www.w3.org/2004/02/skos/core#\": \"skos:\",\n",
    "    \"http://www.w3.org/ns/shacl#\": \"sh:\",\n",
    "    \"http://www.w3.org/2001/XMLSchema#\": \"xsd:\",\n",
    "}\n",
    "\n",
    "def shorten_uri(uri: str) -> str:\n",
    "    \"\"\"Convert full URI to prefixed form for display.\"\"\"\n",
    "    for full, prefix in PREFIXES.items():\n",
    "        if uri.startswith(full):\n",
    "            return prefix + uri[len(full):]\n",
    "    return uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SchemaAnalysisResult:\n",
    "    \"\"\"Result of schema richness detection.\"\"\"\n",
    "    level: int\n",
    "    level_name: str\n",
    "    confidence: str  # \"low\", \"medium\", \"high\"\n",
    "    constructs_found: Dict[str, List[str]]  # {level_name: [constructs]}\n",
    "    triple_count: int\n",
    "    graphs_analyzed: List[str]\n",
    "    has_schema: bool\n",
    "    has_instance_data: bool\n",
    "    owl_imports: List[str] = None  # Detected owl:imports URIs\n",
    "    graph_classifications: Dict[str, str] = None  # {graph: \"schema\"|\"instance\"|\"mixed\"}\n",
    "    recommendations: List[str] = None  # Suggestions for improvement\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.owl_imports is None:\n",
    "            self.owl_imports = []\n",
    "        if self.graph_classifications is None:\n",
    "            self.graph_classifications = {}\n",
    "        if self.recommendations is None:\n",
    "            self.recommendations = []\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            \"level\": self.level,\n",
    "            \"level_name\": self.level_name,\n",
    "            \"confidence\": self.confidence,\n",
    "            \"constructs_found\": self.constructs_found,\n",
    "            \"triple_count\": self.triple_count,\n",
    "            \"graphs_analyzed\": self.graphs_analyzed,\n",
    "            \"has_schema\": self.has_schema,\n",
    "            \"has_instance_data\": self.has_instance_data,\n",
    "            \"owl_imports\": self.owl_imports,\n",
    "            \"graph_classifications\": self.graph_classifications,\n",
    "            \"recommendations\": self.recommendations,\n",
    "        }\n",
    "    \n",
    "    def to_json(self) -> str:\n",
    "        return json.dumps(self.to_dict(), indent=2)\n",
    "\n",
    "\n",
    "def classify_graph(df_graph) -> str:\n",
    "    \"\"\"Classify a graph as schema-heavy, instance-heavy, or mixed.\"\"\"\n",
    "    rdf_type = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"\n",
    "    \n",
    "    # Get types in this graph\n",
    "    types = set(\n",
    "        row.object for row in \n",
    "        df_graph.filter(F.col(\"predicate\") == rdf_type)\n",
    "               .select(\"object\")\n",
    "               .distinct()\n",
    "               .collect()\n",
    "    )\n",
    "    \n",
    "    # Schema types from all levels\n",
    "    schema_types = set()\n",
    "    for level in range(1, 5):\n",
    "        schema_types.update(SCHEMA_INDICATORS[level][\"types\"])\n",
    "    \n",
    "    # Schema predicates\n",
    "    schema_predicates = set()\n",
    "    for level in range(1, 5):\n",
    "        schema_predicates.update(SCHEMA_INDICATORS[level][\"predicates\"])\n",
    "    \n",
    "    predicates = set(row.predicate for row in df_graph.select(\"predicate\").distinct().collect())\n",
    "    \n",
    "    has_schema_types = bool(types & schema_types)\n",
    "    has_schema_predicates = bool(predicates & schema_predicates)\n",
    "    has_instance_types = bool(types - schema_types)\n",
    "    \n",
    "    if has_schema_types or has_schema_predicates:\n",
    "        if has_instance_types:\n",
    "            return \"mixed\"\n",
    "        return \"schema\"\n",
    "    return \"instance\"\n",
    "\n",
    "\n",
    "def detect_owl_imports(df_triples) -> List[str]:\n",
    "    \"\"\"Find owl:imports declarations pointing to external schemas.\"\"\"\n",
    "    owl_imports_uri = \"http://www.w3.org/2002/07/owl#imports\"\n",
    "    \n",
    "    imports = [\n",
    "        row.object for row in \n",
    "        df_triples.filter(F.col(\"predicate\") == owl_imports_uri)\n",
    "                  .select(\"object\")\n",
    "                  .distinct()\n",
    "                  .collect()\n",
    "    ]\n",
    "    return imports\n",
    "\n",
    "\n",
    "def generate_recommendations(\n",
    "    level: int, \n",
    "    has_schema: bool, \n",
    "    has_instance_data: bool,\n",
    "    owl_imports: List[str],\n",
    "    graph_classifications: Dict[str, str]\n",
    ") -> List[str]:\n",
    "    \"\"\"Generate recommendations based on schema analysis.\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    # Count graph types\n",
    "    schema_graphs = sum(1 for c in graph_classifications.values() if c == \"schema\")\n",
    "    instance_graphs = sum(1 for c in graph_classifications.values() if c == \"instance\")\n",
    "    \n",
    "    # Recommendation: Load referenced ontologies\n",
    "    if owl_imports:\n",
    "        recommendations.append(\n",
    "            f\"Found {len(owl_imports)} owl:imports reference(s). Consider loading these \"\n",
    "            f\"ontologies for complete schema information: {', '.join(shorten_uri(u) for u in owl_imports[:3])}\"\n",
    "            + (\"...\" if len(owl_imports) > 3 else \"\")\n",
    "        )\n",
    "    \n",
    "    # Recommendation: Load informative schemas if only instance data\n",
    "    if has_instance_data and not has_schema:\n",
    "        recommendations.append(\n",
    "            \"Data contains only instance triples (level 0). Consider loading the associated \"\n",
    "            \"ontology/schema files (e.g., from 'informative' or 'normative' folders) for \"\n",
    "            \"richer type and property definitions.\"\n",
    "        )\n",
    "    \n",
    "    # Recommendation: Low schema level with instance data\n",
    "    if level == 1 and has_instance_data:\n",
    "        recommendations.append(\n",
    "            \"SKOS vocabulary detected. If your data uses domain classes, consider loading \"\n",
    "            \"the RDFS/OWL ontology for class hierarchy information.\"\n",
    "        )\n",
    "    \n",
    "    # Recommendation: Instance-only graphs detected\n",
    "    if instance_graphs > 0 and schema_graphs > 0:\n",
    "        recommendations.append(\n",
    "            f\"Detected {instance_graphs} instance-only graph(s) and {schema_graphs} schema graph(s). \"\n",
    "            \"Your data is well-structured with separate schema and instance data.\"\n",
    "        )\n",
    "    elif instance_graphs > 0 and schema_graphs == 0:\n",
    "        recommendations.append(\n",
    "            f\"All {instance_graphs} graph(s) contain only instance data. The associated schema/ontology \"\n",
    "            \"may not be loaded. Check for 'informative' or 'normative' TTL files.\"\n",
    "        )\n",
    "    \n",
    "    # Recommendation: Consider SHACL for validation\n",
    "    if level >= 2 and level < 4:\n",
    "        recommendations.append(\n",
    "            f\"Schema level {level} ({SCHEMA_INDICATORS[level]['name']}) detected. \"\n",
    "            \"If SHACL shapes are available, loading them enables data validation.\"\n",
    "        )\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def detect_schema_level(df_triples, graphs: Optional[List[str]] = None) -> SchemaAnalysisResult:\n",
    "    \"\"\"\n",
    "    Detect schema richness level from triples DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df_triples: DataFrame with columns (subject, predicate, object, object_type, graph)\n",
    "        graphs: Optional list of graph names to analyze (None = all)\n",
    "    \n",
    "    Returns:\n",
    "        SchemaAnalysisResult with level, confidence, and found constructs\n",
    "    \"\"\"\n",
    "    # Filter by graphs if specified\n",
    "    if graphs:\n",
    "        df = df_triples.filter(F.col(\"graph\").isin(graphs))\n",
    "    else:\n",
    "        df = df_triples\n",
    "    \n",
    "    # Cache for multiple operations\n",
    "    df.cache()\n",
    "    \n",
    "    triple_count = df.count()\n",
    "    graphs_analyzed = [row.graph for row in df.select(\"graph\").distinct().collect()]\n",
    "    \n",
    "    # Get all unique predicates and types\n",
    "    predicates = set(row.predicate for row in df.select(\"predicate\").distinct().collect())\n",
    "    \n",
    "    # Get types (object values where predicate is rdf:type)\n",
    "    rdf_type = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"\n",
    "    types = set(\n",
    "        row.object for row in \n",
    "        df.filter(F.col(\"predicate\") == rdf_type)\n",
    "          .select(\"object\")\n",
    "          .distinct()\n",
    "          .collect()\n",
    "    )\n",
    "    \n",
    "    # Detect owl:imports\n",
    "    owl_imports = detect_owl_imports(df)\n",
    "    \n",
    "    # Classify each graph\n",
    "    graph_classifications = {}\n",
    "    for graph in graphs_analyzed:\n",
    "        df_graph = df.filter(F.col(\"graph\") == graph)\n",
    "        graph_classifications[graph] = classify_graph(df_graph)\n",
    "    \n",
    "    # Detect constructs at each level (highest to lowest)\n",
    "    constructs_found = {}\n",
    "    detected_level = 0\n",
    "    \n",
    "    for level in [4, 3, 2, 1, 0]:\n",
    "        indicators = SCHEMA_INDICATORS[level]\n",
    "        level_name = indicators[\"name\"]\n",
    "        \n",
    "        # Find matching predicates\n",
    "        found_predicates = [\n",
    "            shorten_uri(p) for p in indicators[\"predicates\"] \n",
    "            if p in predicates\n",
    "        ]\n",
    "        \n",
    "        # Find matching types\n",
    "        found_types = [\n",
    "            shorten_uri(t) for t in indicators[\"types\"]\n",
    "            if t in types\n",
    "        ]\n",
    "        \n",
    "        found_all = found_predicates + found_types\n",
    "        \n",
    "        if found_all:\n",
    "            constructs_found[level_name] = found_all\n",
    "            if level > detected_level:\n",
    "                detected_level = level\n",
    "    \n",
    "    # Determine confidence based on how many indicators found\n",
    "    level_indicators = SCHEMA_INDICATORS[detected_level]\n",
    "    expected_count = len(level_indicators[\"predicates\"]) + len(level_indicators[\"types\"])\n",
    "    found_count = len(constructs_found.get(level_indicators[\"name\"], []))\n",
    "    \n",
    "    if expected_count == 0:\n",
    "        confidence = \"high\"  # Level 0 is always high confidence\n",
    "    elif found_count >= expected_count * 0.5:\n",
    "        confidence = \"high\"\n",
    "    elif found_count >= expected_count * 0.25:\n",
    "        confidence = \"medium\"\n",
    "    else:\n",
    "        confidence = \"low\"\n",
    "    \n",
    "    # Determine if we have schema vs instance data\n",
    "    has_schema = detected_level > 0\n",
    "    \n",
    "    # Check for instance data (subjects that are typed but not schema definitions)\n",
    "    schema_types = set()\n",
    "    for level in range(1, 5):\n",
    "        schema_types.update(SCHEMA_INDICATORS[level][\"types\"])\n",
    "    \n",
    "    instance_types = types - schema_types\n",
    "    has_instance_data = len(instance_types) > 0\n",
    "    \n",
    "    # Generate recommendations\n",
    "    recommendations = generate_recommendations(\n",
    "        detected_level, has_schema, has_instance_data, owl_imports, graph_classifications\n",
    "    )\n",
    "    \n",
    "    df.unpersist()\n",
    "    \n",
    "    return SchemaAnalysisResult(\n",
    "        level=detected_level,\n",
    "        level_name=SCHEMA_INDICATORS[detected_level][\"name\"],\n",
    "        confidence=confidence,\n",
    "        constructs_found=constructs_found,\n",
    "        triple_count=triple_count,\n",
    "        graphs_analyzed=graphs_analyzed,\n",
    "        has_schema=has_schema,\n",
    "        has_instance_data=has_instance_data,\n",
    "        owl_imports=owl_imports,\n",
    "        graph_classifications=graph_classifications,\n",
    "        recommendations=recommendations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bronze triples\n",
    "df_triples = spark.table(INPUT_TABLE)\n",
    "print(f\"Loaded {df_triples.count()} triples from '{INPUT_TABLE}'\")\n",
    "print(f\"Graphs available: {[r.graph for r in df_triples.select('graph').distinct().collect()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all graphs combined\n",
    "result = detect_schema_level(df_triples)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SCHEMA RICHNESS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDetected Level: {result.level} - {result.level_name}\")\n",
    "print(f\"Confidence: {result.confidence}\")\n",
    "print(f\"Total Triples: {result.triple_count}\")\n",
    "print(f\"Graphs Analyzed: {result.graphs_analyzed}\")\n",
    "print(f\"Has Schema: {result.has_schema}\")\n",
    "print(f\"Has Instance Data: {result.has_instance_data}\")\n",
    "print(f\"\\nConstructs Found:\")\n",
    "for level_name, constructs in result.constructs_found.items():\n",
    "    print(f\"  {level_name}: {', '.join(constructs)}\")\n",
    "\n",
    "# Show owl:imports if any\n",
    "if result.owl_imports:\n",
    "    print(f\"\\nüì¶ owl:imports References ({len(result.owl_imports)}):\")\n",
    "    for imp in result.owl_imports:\n",
    "        print(f\"  - {shorten_uri(imp)}\")\n",
    "\n",
    "# Show graph classifications\n",
    "print(f\"\\nüìä Graph Classifications:\")\n",
    "for graph, classification in result.graph_classifications.items():\n",
    "    icon = {\"schema\": \"üìê\", \"instance\": \"üìù\", \"mixed\": \"üîÄ\"}.get(classification, \"‚ùì\")\n",
    "    print(f\"  {icon} {graph}: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each graph individually\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PER-GRAPH ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "graphs = [r.graph for r in df_triples.select(\"graph\").distinct().collect()]\n",
    "graph_results = []\n",
    "\n",
    "for graph in graphs:\n",
    "    result = detect_schema_level(df_triples, graphs=[graph])\n",
    "    graph_results.append(result)\n",
    "    print(f\"\\n{graph}:\")\n",
    "    print(f\"  Level: {result.level} ({result.level_name})\")\n",
    "    print(f\"  Confidence: {result.confidence}\")\n",
    "    print(f\"  Triples: {result.triple_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f701373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display recommendations based on analysis\n",
    "result_all = detect_schema_level(df_triples)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if result_all.recommendations:\n",
    "    for i, rec in enumerate(result_all.recommendations, 1):\n",
    "        print(f\"\\n{i}. {rec}\")\n",
    "else:\n",
    "    print(\"\\n[OK] No recommendations - schema analysis looks complete!\")\n",
    "\n",
    "# Highlight if informative schemas might help\n",
    "instance_only_graphs = [g for g, c in result_all.graph_classifications.items() if c == \"instance\"]\n",
    "if instance_only_graphs and not result_all.has_schema:\n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(\"TIP: Your data appears to be instance-only. If you have access to\")\n",
    "    print(\"informative or normative ontology files (often in separate folders),\")\n",
    "    print(\"loading them will provide:\")\n",
    "    print(\"  - Class hierarchies (rdfs:subClassOf)\")\n",
    "    print(\"  - Property domains and ranges\")\n",
    "    print(\"  - Labels and descriptions for types\")\n",
    "    print(\"  - SHACL shapes for validation (if available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predicate distribution for understanding the data\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREDICATE DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_triples.groupBy(\"predicate\") \\\n",
    "    .count() \\\n",
    "    .orderBy(F.desc(\"count\")) \\\n",
    "    .show(30, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show type distribution (rdf:type objects)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TYPE DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rdf_type = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"\n",
    "df_triples.filter(F.col(\"predicate\") == rdf_type) \\\n",
    "    .groupBy(\"object\") \\\n",
    "    .count() \\\n",
    "    .orderBy(F.desc(\"count\")) \\\n",
    "    .show(30, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55863e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export result to JSON (for frontend consumption)\n",
    "result_combined = detect_schema_level(df_triples)\n",
    "result_json = result_combined.to_json()\n",
    "print(\"\\nJSON Output (for frontend):\")\n",
    "print(result_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3029673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save results to Delta table for pipeline use\n",
    "from pyspark.sql import Row\n",
    "from datetime import datetime\n",
    "\n",
    "result_row = Row(\n",
    "    analysis_timestamp=datetime.now().isoformat(),\n",
    "    level=result_combined.level,\n",
    "    level_name=result_combined.level_name,\n",
    "    confidence=result_combined.confidence,\n",
    "    triple_count=result_combined.triple_count,\n",
    "    graphs_analyzed=result_combined.graphs_analyzed,\n",
    "    has_schema=result_combined.has_schema,\n",
    "    has_instance_data=result_combined.has_instance_data,\n",
    "    constructs_json=json.dumps(result_combined.constructs_found)\n",
    ")\n",
    "\n",
    "df_result = spark.createDataFrame([result_row])\n",
    "\n",
    "df_result.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(OUTPUT_TABLE)\n",
    "\n",
    "print(f\"\\nResults saved to '{OUTPUT_TABLE}'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
